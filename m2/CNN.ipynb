{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem: Implement a CNN for CIFAR-10 in PyTorch\n",
    "\n",
    "### Problem Statement\n",
    "You are tasked with implementing a **Convolutional Neural Network (CNN)** for image classification on the **CIFAR-10** dataset using PyTorch. The model should contain convolutional layers for feature extraction, pooling layers for downsampling, and fully connected layers for classification. Your goal is to complete the CNN model by defining the necessary layers and implementing the forward pass.\n",
    "\n",
    "### Requirements\n",
    "1. **Define the CNN Model**:\n",
    "   - Add **convolutional layers** for feature extraction.\n",
    "   - Add **pooling layers** to reduce the spatial dimensions.\n",
    "   - Add **fully connected layers** to output class predictions.\n",
    "   - The model should be capable of processing input images of size `(32x32x3)` as in the CIFAR-10 dataset.\n",
    "\n",
    "### Constraints\n",
    "- The CNN should be designed with multiple convolutional and pooling layers followed by fully connected layers.\n",
    "- Ensure the model is compatible with the CIFAR-10 dataset, which contains 10 classes.\n",
    "\n",
    "\n",
    "<details>\n",
    "  <summary>💡 Hint</summary>\n",
    "  Add the convolutional (conv1, conv2), pooling (pool), and fully connected layers (fc1, fc2) in CNNModel.__init__.\n",
    "  <br>\n",
    "  Implement the forward pass to process inputs through these layers.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-15T05:35:40.240740Z",
     "start_time": "2025-02-15T05:35:40.236751Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-15T05:35:35.520465Z",
     "start_time": "2025-02-15T05:35:15.103344Z"
    }
   },
   "source": [
    "# Load CIFAR-10 dataset\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=False)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data\\cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\cifar-10-python.tar.gz to ./data\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-15T13:25:07.706895Z",
     "start_time": "2025-02-15T13:25:07.647262Z"
    }
   },
   "source": [
    "data = iter(train_loader)\n",
    "x = next(data)\n",
    "(img, cls) = x# Batch, channels, Height, Width(Default config for Conv2d)\n",
    "conv_test = nn.Conv2d(in_channels=3, out_channels=8,kernel_size=3, padding=1)\n",
    "conv_test(img).shape\n",
    "\n",
    "# 그대로 먹여주면 됩니다. 알잘딱 해줄겁니다. 우리가 할건 계산밖에 없어요"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 8, 32, 32])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-15T05:35:40.333514Z",
     "start_time": "2025-02-15T05:35:40.326632Z"
    }
   },
   "source": [
    "# Define the CNN Model\n",
    "# TODO: Add convolutional, pooling, and fully connected layers\n",
    "# 스터디 Goals\n",
    "# 1. 이미지에 대해 convolutional을 Conv2d를 활용해 적용하는 방법을 안다.\n",
    "# 여기서 Conv2d의 파라미터의 역할과, 어떻게 차원이 변경하는지를 정리해준다.\n",
    "# 2. 최종적으로 flatten을 진행해 FCN에 먹여야 한다. 이를 어떻게 차원을 찾고, 제대로 flatten 하는 방법\n",
    "# 3. 아마 dtype 쪽 문제도 있을 가능성이 있다. 이 부분을 확인해야 하겠다.\n",
    "# 레퍼런스는 토치쪽 docs다. 한번 F.ReLU, nn.ReLU도 살짝 다뤄야 할듯\n",
    "# https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html, https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html, https://discuss.pytorch.org/t/whats-the-difference-between-nn-relu-vs-f-relu/27599\n",
    "# 4. ReLU의 활용과 pooling을 어떨때 해야 하는지에 대한 정보가 필요하다\n",
    "# https://cs231n.github.io/convolutional-networks/\n",
    "class CNNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=8, kernel_size=3, stride=1, padding=1) # 데이터 shape은 64, 8, 32, 32입니다\n",
    "        self.conv2 = nn.Conv2d(in_channels=8, out_channels=16, kernel_size=9, stride=1, padding=0) # 꽉 잡고 채널 수는 증가, 이미지 차원수는 감소하겠습니다. 64, 16, 24, 24로 바꿉니다.\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fcn = nn.Sequential(\n",
    "            nn.Linear(in_features=16*12*12, out_features=12*12),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=12*12, out_features=10)\n",
    "        )\n",
    "        self.relu = nn.ReLU()\n",
    "    def forward(self, x):\n",
    "        # cs231n을 확인해보니, 각 합성곱 레이어 다음에는 ReLU(활성화 함수)를 적용하고 최종적으로 차원을 확 줄여야 할때 pooling을 쓴다 한다.\n",
    "        # 따라서 Conv와 ReLU 두번 하고 그다음에 pooling, 그 뒤에 FFN 하겠습니다.\n",
    "        x = nn.functional.relu(self.conv1(x)) # 64, 8, 32, 32\n",
    "        x = nn.functional.relu(self.conv2(x)) # 64, 16, 24, 24\n",
    "        x = self.pool(x) # 64, 16, 12, 12\n",
    "        x = torch.flatten(x, 1) # Batch까지 1차원으로 변경하면 큰일남\n",
    "        x = self.fcn(x)\n",
    "\n",
    "        return x"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-15T05:43:55.668288Z",
     "start_time": "2025-02-15T05:35:40.359947Z"
    }
   },
   "source": [
    "# Initialize the model, loss function, and optimizer\n",
    "model = CNNModel()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    for images, labels in train_loader:\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f\"Epoch [{epoch + 1}/{epochs}], Loss: {loss.item():.4f}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 1.1098\n",
      "Epoch [2/10], Loss: 1.0286\n",
      "Epoch [3/10], Loss: 0.9075\n",
      "Epoch [4/10], Loss: 1.0550\n",
      "Epoch [5/10], Loss: 0.8824\n",
      "Epoch [6/10], Loss: 1.0673\n",
      "Epoch [7/10], Loss: 0.6515\n",
      "Epoch [8/10], Loss: 1.1646\n",
      "Epoch [9/10], Loss: 0.8996\n",
      "Epoch [10/10], Loss: 1.1356\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-15T05:44:04.026922Z",
     "start_time": "2025-02-15T05:44:00.918505Z"
    }
   },
   "source": [
    "# Evaluate on the test set\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Test Accuracy: {100 * correct / total:.2f}%\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 62.54%\n"
     ]
    }
   ],
   "execution_count": 9
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
