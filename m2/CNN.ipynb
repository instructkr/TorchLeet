{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem: Implement a CNN for CIFAR-10 in PyTorch\n",
    "\n",
    "### Problem Statement\n",
    "You are tasked with implementing a **Convolutional Neural Network (CNN)** for image classification on the **CIFAR-10** dataset using PyTorch. The model should contain convolutional layers for feature extraction, pooling layers for downsampling, and fully connected layers for classification. Your goal is to complete the CNN model by defining the necessary layers and implementing the forward pass.\n",
    "\n",
    "### Requirements\n",
    "1. **Define the CNN Model**:\n",
    "   - Add **convolutional layers** for feature extraction.\n",
    "   - Add **pooling layers** to reduce the spatial dimensions.\n",
    "   - Add **fully connected layers** to output class predictions.\n",
    "   - The model should be capable of processing input images of size `(32x32x3)` as in the CIFAR-10 dataset.\n",
    "\n",
    "### Constraints\n",
    "- The CNN should be designed with multiple convolutional and pooling layers followed by fully connected layers.\n",
    "- Ensure the model is compatible with the CIFAR-10 dataset, which contains 10 classes.\n",
    "\n",
    "\n",
    "<details>\n",
    "  <summary>ğŸ’¡ Hint</summary>\n",
    "  Add the convolutional (conv1, conv2), pooling (pool), and fully connected layers (fc1, fc2) in CNNModel.__init__.\n",
    "  <br>\n",
    "  Implement the forward pass to process inputs through these layers.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-15T05:35:40.240740Z",
     "start_time": "2025-02-15T05:35:40.236751Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-15T05:35:35.520465Z",
     "start_time": "2025-02-15T05:35:15.103344Z"
    }
   },
   "source": [
    "# Load CIFAR-10 dataset\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=False)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data\\cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\cifar-10-python.tar.gz to ./data\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-15T13:25:07.706895Z",
     "start_time": "2025-02-15T13:25:07.647262Z"
    }
   },
   "source": [
    "data = iter(train_loader)\n",
    "x = next(data)\n",
    "(img, cls) = x# Batch, channels, Height, Width(Default config for Conv2d)\n",
    "conv_test = nn.Conv2d(in_channels=3, out_channels=8,kernel_size=3, padding=1)\n",
    "conv_test(img).shape\n",
    "\n",
    "# ê·¸ëŒ€ë¡œ ë¨¹ì—¬ì£¼ë©´ ë©ë‹ˆë‹¤. ì•Œì˜ë”± í•´ì¤„ê²ë‹ˆë‹¤. ìš°ë¦¬ê°€ í• ê±´ ê³„ì‚°ë°–ì— ì—†ì–´ìš”"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 8, 32, 32])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-15T05:35:40.333514Z",
     "start_time": "2025-02-15T05:35:40.326632Z"
    }
   },
   "source": [
    "# Define the CNN Model\n",
    "# TODO: Add convolutional, pooling, and fully connected layers\n",
    "# ìŠ¤í„°ë”” Goals\n",
    "# 1. ì´ë¯¸ì§€ì— ëŒ€í•´ convolutionalì„ Conv2dë¥¼ í™œìš©í•´ ì ìš©í•˜ëŠ” ë°©ë²•ì„ ì•ˆë‹¤.\n",
    "# ì—¬ê¸°ì„œ Conv2dì˜ íŒŒë¼ë¯¸í„°ì˜ ì—­í• ê³¼, ì–´ë–»ê²Œ ì°¨ì›ì´ ë³€ê²½í•˜ëŠ”ì§€ë¥¼ ì •ë¦¬í•´ì¤€ë‹¤.\n",
    "# 2. ìµœì¢…ì ìœ¼ë¡œ flattenì„ ì§„í–‰í•´ FCNì— ë¨¹ì—¬ì•¼ í•œë‹¤. ì´ë¥¼ ì–´ë–»ê²Œ ì°¨ì›ì„ ì°¾ê³ , ì œëŒ€ë¡œ flatten í•˜ëŠ” ë°©ë²•\n",
    "# 3. ì•„ë§ˆ dtype ìª½ ë¬¸ì œë„ ìˆì„ ê°€ëŠ¥ì„±ì´ ìˆë‹¤. ì´ ë¶€ë¶„ì„ í™•ì¸í•´ì•¼ í•˜ê² ë‹¤.\n",
    "# ë ˆí¼ëŸ°ìŠ¤ëŠ” í† ì¹˜ìª½ docsë‹¤. í•œë²ˆ F.ReLU, nn.ReLUë„ ì‚´ì§ ë‹¤ë¤„ì•¼ í• ë“¯\n",
    "# https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html, https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html, https://discuss.pytorch.org/t/whats-the-difference-between-nn-relu-vs-f-relu/27599\n",
    "# 4. ReLUì˜ í™œìš©ê³¼ poolingì„ ì–´ë–¨ë•Œ í•´ì•¼ í•˜ëŠ”ì§€ì— ëŒ€í•œ ì •ë³´ê°€ í•„ìš”í•˜ë‹¤\n",
    "# https://cs231n.github.io/convolutional-networks/\n",
    "class CNNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=8, kernel_size=3, stride=1, padding=1) # ë°ì´í„° shapeì€ 64, 8, 32, 32ì…ë‹ˆë‹¤\n",
    "        self.conv2 = nn.Conv2d(in_channels=8, out_channels=16, kernel_size=9, stride=1, padding=0) # ê½‰ ì¡ê³  ì±„ë„ ìˆ˜ëŠ” ì¦ê°€, ì´ë¯¸ì§€ ì°¨ì›ìˆ˜ëŠ” ê°ì†Œí•˜ê² ìŠµë‹ˆë‹¤. 64, 16, 24, 24ë¡œ ë°”ê¿‰ë‹ˆë‹¤.\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fcn = nn.Sequential(\n",
    "            nn.Linear(in_features=16*12*12, out_features=12*12),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=12*12, out_features=10)\n",
    "        )\n",
    "        self.relu = nn.ReLU()\n",
    "    def forward(self, x):\n",
    "        # cs231nì„ í™•ì¸í•´ë³´ë‹ˆ, ê° í•©ì„±ê³± ë ˆì´ì–´ ë‹¤ìŒì—ëŠ” ReLU(í™œì„±í™” í•¨ìˆ˜)ë¥¼ ì ìš©í•˜ê³  ìµœì¢…ì ìœ¼ë¡œ ì°¨ì›ì„ í™• ì¤„ì—¬ì•¼ í• ë•Œ poolingì„ ì“´ë‹¤ í•œë‹¤.\n",
    "        # ë”°ë¼ì„œ Convì™€ ReLU ë‘ë²ˆ í•˜ê³  ê·¸ë‹¤ìŒì— pooling, ê·¸ ë’¤ì— FFN í•˜ê² ìŠµë‹ˆë‹¤.\n",
    "        x = nn.functional.relu(self.conv1(x)) # 64, 8, 32, 32\n",
    "        x = nn.functional.relu(self.conv2(x)) # 64, 16, 24, 24\n",
    "        x = self.pool(x) # 64, 16, 12, 12\n",
    "        x = torch.flatten(x, 1) # Batchê¹Œì§€ 1ì°¨ì›ìœ¼ë¡œ ë³€ê²½í•˜ë©´ í°ì¼ë‚¨\n",
    "        x = self.fcn(x)\n",
    "\n",
    "        return x"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-15T05:43:55.668288Z",
     "start_time": "2025-02-15T05:35:40.359947Z"
    }
   },
   "source": [
    "# Initialize the model, loss function, and optimizer\n",
    "model = CNNModel()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    for images, labels in train_loader:\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f\"Epoch [{epoch + 1}/{epochs}], Loss: {loss.item():.4f}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 1.1098\n",
      "Epoch [2/10], Loss: 1.0286\n",
      "Epoch [3/10], Loss: 0.9075\n",
      "Epoch [4/10], Loss: 1.0550\n",
      "Epoch [5/10], Loss: 0.8824\n",
      "Epoch [6/10], Loss: 1.0673\n",
      "Epoch [7/10], Loss: 0.6515\n",
      "Epoch [8/10], Loss: 1.1646\n",
      "Epoch [9/10], Loss: 0.8996\n",
      "Epoch [10/10], Loss: 1.1356\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-15T05:44:04.026922Z",
     "start_time": "2025-02-15T05:44:00.918505Z"
    }
   },
   "source": [
    "# Evaluate on the test set\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Test Accuracy: {100 * correct / total:.2f}%\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 62.54%\n"
     ]
    }
   ],
   "execution_count": 9
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
